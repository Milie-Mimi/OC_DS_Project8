{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef280d3",
   "metadata": {},
   "source": [
    "# Projet 8: Déployez un modèle dans le cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1753f624",
   "metadata": {},
   "source": [
    "Fruits est une start-up de l'agri-tech qui a pour volonté de préserver la **biodiversité des fruits** en développant des **robots cueilleurs intelligents** qui appliqueraient des **traitements spécifiques à chaque espèce** de fruits lors de la récolte.\n",
    "\n",
    "Pour se faire connaître auprès du grand public, elle souhaite mettre à sa disposition une **application mobile** qui permettrait aux utilisateurs de **prendre en photo** un fruit et d'obtenir des **informations** sur ce dernier. Trois principaux objectifs:\n",
    "- sensibiliser le grand public à la biodiversité des fruits\n",
    "- mettre en place une première version du moteur de classification des images de fruits\n",
    "- construire une première version de l'architecture Big Data nécessaire\n",
    "\n",
    "**Contraintes à prendre en compte:**\n",
    "- le **volume des données va augmenter très rapidement** après la livraison de ce projet => architecture Big Data avec scripts en Pyspark\n",
    "- compléter le script d'un **traitement de diffusion des poids du modèle Tensorflow sur les clusters**\n",
    "- compléter le script d'une étape de **réduction de dimension de type PCA** en PySpark\n",
    "- les **serveurs** doivent être situés sur le **territoire européen**\n",
    "- faire un **retour critique** sur le choix de l'architecture Big Data choisie\n",
    "\n",
    "Ce notebook contient les **scripts en PySpark exécutables** sur **Databricks** c'est à dire les **étapes de preprocessing** et la **réduction de dimension** de type PCA (Principal Component Analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84669786",
   "metadata": {},
   "source": [
    "## Table des matières: <a class=\"anchor\" id=\"0\"></a>\n",
    "\n",
    "\n",
    "1. [Introduction au Big Data](#bigdata)\n",
    "2. [Choix d'utiliser Databricks](#databricks)\n",
    "3. [Import des librairies et configurations générales](#library)\n",
    "3. [Preprocessing des données](#preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04e6b2b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Introduction au Big Data <a class=\"anchor\" id=\"bigdata\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a37a73",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Le **web 3.0** est celui de la **mobilité**, des **objets connectés** et des **données**. C'est un web sémantique où l'internaute est \"fiché\", notamment au travers de sa navigation et de ses différents profils sur les réseaux sociaux. \n",
    "\n",
    "L'**utilisation massive** d'internet et des objets connectés comme le téléphone, l'ordinateur, la montre, la balance etc engendre la **production de quantités astronomiques de données** ce qui pose des **problématiques de stockage et de traitement approprié** pour les entreprises qui les exploitent afin de prendre notamment des décisions stratégiques et concurrentielles.\n",
    "\n",
    "Cette infographie offre une vision très parlante du monde de la donnée aujourd'hui:\n",
    "\n",
    "![Data](img/data_infographie.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcf81ea",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A titre d'exemple, en 2009, 800 000 pétaoctets de données étaient produits, 35 zettaoctets en 2020 et plus de 180 zettaoctets de données prévus d'ici 2025 (*5 en 5 ans!).\n",
    "\n",
    "Il faut donc des **technologies innovantes** capables de traiter:\n",
    "- des volumes de données énormes et en constante augmentation\n",
    "- des données provenant de sources multiples et de natures diverses\n",
    "- des besoins analytiques vitaux à fournir dans des délais impartis\n",
    "\n",
    "Le Big Data désigne le courant technologique que nous voyons émerger ces dernières années autour des données, des **mégadonnées que nous permettent de stocker aujourd’hui les serveurs**. Le Big Data vient du fait que les données de certaines entreprises ou institutions sont devenues tellement volumineuses que les outils techniques classiques de gestion, de requête sur les bases dites structurées et de traitement des données sont devenus obsolètes, avec des difficultés dans l’instanciation de celles-ci, les temps d’extraction, de traitement devenant trop long.\n",
    "\n",
    "Le socle commun sur lequel à peu près tout le monde s’entend pour caractériser les problématiques de Big Data, ce sont les 4V : Volume, Vitesse, Variété et Véracité.\n",
    "- **Volume** : des volumes de données énormes en constante augmentation\n",
    "- **Vitesse** : des besoins analytiques importants à fournir dans des délais impartis\n",
    "- **Varieté** : des données provenant de sources multiples et de natures diverses\n",
    "- **Véracité** : fait référence à la fiabilité de la donnée, la qualité et la précision sont moins vérifiables\n",
    "\n",
    "Le choix de l'**architecture de données** à mettre en place est donc essentiel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d86a9ca",
   "metadata": {},
   "source": [
    "## Choix d'utiliser Databricks <a class=\"anchor\" id=\"databricks\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1059cafa",
   "metadata": {},
   "source": [
    "Plusieurs raisons m'ont poussé à transférer les traitements sur Databricks qui est un environnement SaaS (Software-as-a-Service) permettant d'accéder aux données et aux ressources de calcul:\n",
    "\n",
    "![Databricks](img/databricks_logo.png)\n",
    "\n",
    "- **simplicité**: Databricks permet une seule architecture de données unifiée sur S3 (solution de stockage des données sur Amazon) pour l'analytique SQL, la data science et le machine learning\n",
    "- **rapport performance / prix**: performances du data warehouse au prix d'un data lake grâce à des clusters de calcul optimisés par SQL\n",
    "- **réputation**: des clients prestigieux comme HP, Nasdac, Hotels.com ont mis en œuvre Databricks sur AWS pour mettre à disposition une plateforme d'analytique révolutionnaire répondant à tous les cas d'usage de l'analytique et de l'IA.\n",
    "\n",
    "Construire des modèles de ML est difficile et les mettre en production est encore plus difficile:\n",
    "- la **diversité des frameworks de ML** complique la gestion des environnements de ML\n",
    "- les **transferts entre équipes sont difficile**s en raison de la disparité des outils et des processus, de la préparation des données à l'expérimentation et à la production\n",
    "- la difficulté de suivre les expériences, les modèles, les dépendances et les artefacts rend **difficile la reproduction des résultats**\n",
    "- il y a des **risques liés à la sécurité et à la conformité**\n",
    "\n",
    "Le maintien de la qualité des données et de la précision des modèles au fil du temps ne sont que quelques-uns des défis à relever. Databricks va **rationaliser le développement ML**, de la préparation des données à l'entraînement et au déploiement des modèles, à **grande échelle** tout en permettant la collaboration:\n",
    "- **workspace**: un lieu central pour stocker et partager des notebooks, des expériences et des projets, avec un contrôle d'accès basé sur les rôles\n",
    "- **notebooks** collaboratifs: prise en charge de plusieurs langues (R, Python, SQL, Scala) et le versionning intégré permettent aux équipes de partager et d'itérer sur le code plus rapidement\n",
    "- **AutoML**: obtention de résultats plus rapides grâce à l'ajustement automatique des hyperparamètres et à la recherche de modèles avec les intégrations Hyperopt, Apache SparkTM et MLflow\n",
    "- **Experiments Tracking**: suivre automatiquement les expériences et utiliser les visualisations intégrées pour voir et comparer les résultats de milliers d'essais, sélectionner les paramètres, les mesures et identifier le meilleur essai.\n",
    "- **Model Registry**: enregistrer le modèle à mettre en production dans un seul endroit et gérer son cycle de vie de manière collaborative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e8188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet8",
   "language": "python",
   "name": "projet8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
